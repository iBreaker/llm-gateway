# LLM Gateway API æ ¼å¼è§„èŒƒ

æœ¬æ–‡æ¡£è¯¦ç»†æè¿°äº†LLM Gatewayæ”¯æŒçš„ä¸¤ç§ä¸»è¦APIæ ¼å¼ï¼šOpenAIæ ¼å¼å’ŒAnthropicæ ¼å¼ã€‚

## ç›®å½•

1. [æ ¸å¿ƒå·®å¼‚å¯¹æ¯”](#æ ¸å¿ƒå·®å¼‚å¯¹æ¯”)
2. [OpenAI API æ ¼å¼](#openai-api-æ ¼å¼)
3. [Anthropic API æ ¼å¼](#anthropic-api-æ ¼å¼)
4. [æ ¼å¼æ£€æµ‹è§„åˆ™](#æ ¼å¼æ£€æµ‹è§„åˆ™)
5. [æ ¼å¼è½¬æ¢æ˜ å°„](#æ ¼å¼è½¬æ¢æ˜ å°„)
6. [é”™è¯¯å“åº”æ ¼å¼](#é”™è¯¯å“åº”æ ¼å¼)
7. [Streamæ ¼å¼è§„èŒƒ](#streamæ ¼å¼è§„èŒƒ)
8. [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## æ ¸å¿ƒå·®å¼‚å¯¹æ¯”

### ğŸ“Š ä¸»è¦ç‰¹æ€§å¯¹æ¯”

| ç‰¹æ€§ | OpenAI | Anthropic |
|------|--------|-----------|
| **ä¸»è¦ç«¯ç‚¹** | `/v1/chat/completions` | `/v1/messages` |
| **ç³»ç»Ÿæ¶ˆæ¯** | `messages`æ•°ç»„ä¸­çš„`system`è§’è‰² | ç‹¬ç«‹çš„`system`å­—æ®µ |
| **å¿…éœ€å­—æ®µ** | `model`, `messages` | `model`, `max_tokens`, `messages` |
| **æ¨¡å‹å‘½å** | `gpt-4o`, `gpt-4o-mini` | `claude-3-5-sonnet`, `claude-3-5-haiku` |
| **åœæ­¢å‚æ•°** | `stop` (array/string) | `stop_sequences` (array) |
| **Tokenç»Ÿè®¡** | `prompt_tokens`, `completion_tokens` | `input_tokens`, `output_tokens` |
| **æ¸©åº¦èŒƒå›´** | 0.0 - 2.0 | 0.0 - 1.0 |
| **è§’è‰²æ”¯æŒ** | `system`, `user`, `assistant`, `function` | `user`, `assistant` |

### ğŸ”§ è¯·æ±‚æ ¼å¼å¯¹æ¯”

**OpenAI è¯·æ±‚ç¤ºä¾‹ï¼š**
```json
{
  "model": "gpt-4o",
  "messages": [
    {"role": "system", "content": "You are helpful."},
    {"role": "user", "content": "Hello!"}
  ],
  "max_tokens": 100,
  "temperature": 0.7,
  "stop": ["Human:", "AI:"]
}
```

**Anthropic è¯·æ±‚ç¤ºä¾‹ï¼š**
```json
{
  "model": "claude-3-5-sonnet",
  "max_tokens": 100,
  "system": "You are helpful.",
  "messages": [
    {"role": "user", "content": "Hello!"}
  ],
  "temperature": 0.7,
  "stop_sequences": ["Human:", "AI:"]
}
```

### ğŸ“¤ å“åº”æ ¼å¼å¯¹æ¯”

**OpenAI å“åº”ï¼š**
```json
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "choices": [{
    "message": {
      "role": "assistant",
      "content": "Hello! How can I help you?"
    },
    "finish_reason": "stop"
  }],
  "usage": {
    "prompt_tokens": 20,
    "completion_tokens": 10,
    "total_tokens": 30
  }
}
```

**Anthropic å“åº”ï¼š**
```json
{
  "id": "msg_123", 
  "type": "message",
  "role": "assistant",
  "content": [{
    "type": "text",
    "text": "Hello! How can I help you?"
  }],
  "stop_reason": "end_turn",
  "usage": {
    "input_tokens": 20,
    "output_tokens": 10
  }
}
```

---

## OpenAI API æ ¼å¼

### è¯·æ±‚æ ¼å¼

**å®Œæ•´è¯·æ±‚ç¤ºä¾‹ï¼š**
```json
{
  "model": "gpt-4o",
  "messages": [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Hello!"}
  ],
  "max_tokens": 100,
  "temperature": 0.7,
  "top_p": 1.0,
  "n": 1,
  "stream": false,
  "stop": ["Human:", "AI:"],
  "presence_penalty": 0.0,
  "frequency_penalty": 0.0,
  "logit_bias": {},
  "user": "user123"
}
```

**å¿…éœ€å­—æ®µï¼š**
- `model`: æ¨¡å‹æ ‡è¯†ç¬¦
- `messages`: å¯¹è¯æ¶ˆæ¯æ•°ç»„

**å¯é€‰å­—æ®µï¼š**
- `max_tokens`: æœ€å¤§ç”Ÿæˆtokenæ•°
- `temperature`: æ¸©åº¦å‚æ•° (0.0-2.0)
- `top_p`: æ ¸é‡‡æ ·å‚æ•°
- `n`: ç”Ÿæˆå›å¤æ•°é‡
- `stream`: æ˜¯å¦æµå¼å“åº”
- `stop`: åœæ­¢åºåˆ—
- `presence_penalty`: å­˜åœ¨æƒ©ç½š
- `frequency_penalty`: é¢‘ç‡æƒ©ç½š
- `logit_bias`: å¯¹æ•°åå·®
- `user`: ç”¨æˆ·æ ‡è¯†

### å“åº”æ ¼å¼

**æˆåŠŸå“åº”ï¼š**
```json
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "created": 1677652288,
  "model": "gpt-4o",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Hello! How can I help you today?"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 20,
    "completion_tokens": 10,
    "total_tokens": 30
  }
}
```

**å­—æ®µè¯´æ˜ï¼š**

| å­—æ®µ | ç±»å‹ | å¿…éœ€ | æè¿° |
|------|------|------|------|
| `id` | string | âœ… | å“åº”å”¯ä¸€æ ‡è¯†ç¬¦ |
| `object` | string | âœ… | å¯¹è±¡ç±»å‹ |
| `created` | integer | âœ… | åˆ›å»ºæ—¶é—´æˆ³ |
| `model` | string | âœ… | æ¨¡å‹æ ‡è¯†ç¬¦ (å¦‚: gpt-4o, gpt-4o-mini) |
| `choices` | array | âœ… | ç”Ÿæˆçš„é€‰æ‹©åˆ—è¡¨ |
| `usage` | object | âœ… | Tokenä½¿ç”¨ç»Ÿè®¡ |

**Choices å­—æ®µï¼š**

| å­—æ®µ | ç±»å‹ | å¿…éœ€ | æè¿° |
|------|------|------|------|
| `index` | integer | âœ… | é€‰æ‹©ç´¢å¼• |
| `message` | object | âœ… | ç”Ÿæˆçš„æ¶ˆæ¯ |
| `finish_reason` | string | âœ… | å®ŒæˆåŸå›  |

**Usage å­—æ®µï¼š**

| å­—æ®µ | ç±»å‹ | å¿…éœ€ | æè¿° |
|------|------|------|------|
| `prompt_tokens` | integer | âœ… | è¾“å…¥tokenæ•° |
| `completion_tokens` | integer | âœ… | è¾“å‡ºtokenæ•° |
| `total_tokens` | integer | âœ… | æ€»tokenæ•° |

---

## Anthropic API æ ¼å¼

### è¯·æ±‚æ ¼å¼

**å®Œæ•´è¯·æ±‚ç¤ºä¾‹ï¼š**
```json
{
  "model": "claude-3-5-sonnet-20241022",
  "max_tokens": 100,
  "system": "You are a helpful assistant.",
  "messages": [
    {"role": "user", "content": "Hello!"}
  ],
  "temperature": 0.7,
  "top_p": 1.0,
  "top_k": 40,
  "stop_sequences": ["Human:", "AI:"],
  "stream": false,
  "metadata": {
    "user_id": "user123"
  }
}
```

**å¿…éœ€å­—æ®µï¼š**
- `model`: æ¨¡å‹æ ‡è¯†ç¬¦
- `max_tokens`: æœ€å¤§ç”Ÿæˆtokenæ•°
- `messages`: å¯¹è¯æ¶ˆæ¯æ•°ç»„

**å¯é€‰å­—æ®µï¼š**
- `system`: ç³»ç»Ÿæç¤ºè¯
- `temperature`: æ¸©åº¦å‚æ•° (0.0-1.0)
- `top_p`: æ ¸é‡‡æ ·å‚æ•°
- `top_k`: Top-Ké‡‡æ ·å‚æ•°
- `stop_sequences`: åœæ­¢åºåˆ—æ•°ç»„
- `stream`: æ˜¯å¦æµå¼å“åº”
- `metadata`: å…ƒæ•°æ®

### å“åº”æ ¼å¼

**æˆåŠŸå“åº”ï¼š**
```json
{
  "id": "msg_123",
  "type": "message",
  "role": "assistant",
  "content": [
    {
      "type": "text",
      "text": "Hello! How can I help you today?"
    }
  ],
  "model": "claude-3-5-sonnet-20241022",
  "stop_reason": "end_turn",
  "stop_sequence": null,
  "usage": {
    "input_tokens": 20,
    "output_tokens": 10
  }
}
```

**å­—æ®µè¯´æ˜ï¼š**

| å­—æ®µ | ç±»å‹ | å¿…éœ€ | æè¿° |
|------|------|------|------|
| `id` | string | âœ… | å“åº”å”¯ä¸€æ ‡è¯†ç¬¦ |
| `type` | string | âœ… | æ¶ˆæ¯ç±»å‹ |
| `role` | string | âœ… | è§’è‰²æ ‡è¯† |
| `content` | array | âœ… | å†…å®¹æ•°ç»„ |
| `model` | string | âœ… | æ¨¡å‹æ ‡è¯†ç¬¦ (å¦‚: claude-3-5-sonnet-20241022) |
| `stop_reason` | string | âœ… | åœæ­¢åŸå›  |
| `stop_sequence` | string/null | âœ… | è§¦å‘çš„åœæ­¢åºåˆ— |
| `usage` | object | âœ… | Tokenä½¿ç”¨ç»Ÿè®¡ |

**Content å­—æ®µï¼š**

| å­—æ®µ | ç±»å‹ | å¿…éœ€ | æè¿° |
|------|------|------|------|
| `type` | string | âœ… | å†…å®¹ç±»å‹ (text, image) |
| `text` | string | âœ… | æ–‡æœ¬å†…å®¹ |

**Usage å­—æ®µï¼š**

| å­—æ®µ | ç±»å‹ | å¿…éœ€ | æè¿° |
|------|------|------|------|
| `input_tokens` | integer | âœ… | è¾“å…¥tokenæ•° |
| `output_tokens` | integer | âœ… | è¾“å‡ºtokenæ•° |

### æ”¯æŒçš„æ¨¡å‹

| æ¨¡å‹åç§° | æ ‡è¯†ç¬¦ | æè¿° |
|----------|--------|------|
| Claude 3.5 Sonnet | `claude-3-5-sonnet-20241022` | å¹³è¡¡æ€§èƒ½å’Œé€Ÿåº¦ |
| Claude 3.5 Haiku | `claude-3-5-haiku-20241022` | å¿«é€Ÿå“åº”æ¨¡å‹ |

---

## æ ¼å¼æ£€æµ‹è§„åˆ™

### æ£€æµ‹é€»è¾‘

Gatewayä¼šè‡ªåŠ¨æ£€æµ‹è¯·æ±‚æ ¼å¼å¹¶è½¬æ¢ä¸ºç›¸åº”çš„ä¸Šæ¸¸æ ¼å¼ï¼š

1. **OpenAIæ ¼å¼æ£€æµ‹**ï¼š
   - ç«¯ç‚¹ï¼š`/v1/chat/completions`
   - å¿…éœ€å­—æ®µï¼š`model`, `messages`
   - å¯é€‰å­—æ®µï¼š`max_tokens`, `temperature`, `top_p`, `n`, `stream`, `stop`

2. **Anthropicæ ¼å¼æ£€æµ‹**ï¼š
   - ç«¯ç‚¹ï¼š`/v1/messages`
   - å¿…éœ€å­—æ®µï¼š`model`, `max_tokens`, `messages`
   - å¯é€‰å­—æ®µï¼š`system`, `temperature`, `top_p`, `top_k`, `stop_sequences`, `stream`

### è½¬æ¢æ˜ å°„

**OpenAI â†’ Anthropicï¼š**
```json
// è¾“å…¥ (OpenAIæ ¼å¼)
{
  "model": "gpt-4o",
  "messages": [
    {"role": "system", "content": "You are helpful."},
    {"role": "user", "content": "Hello!"}
  ],
  "max_tokens": 100,
  "temperature": 0.7,
  "stop": ["Human:", "AI:"]
}

// è½¬æ¢å (Anthropicæ ¼å¼)
{
  "model": "claude-3-5-sonnet",
  "max_tokens": 100,
  "system": "You are helpful.",
  "messages": [
    {"role": "user", "content": "Hello!"}
  ],
  "temperature": 0.7,
  "stop_sequences": ["Human:", "AI:"]
}
```

**Anthropic â†’ OpenAIï¼š**
```json
// è¾“å…¥ (Anthropicæ ¼å¼)
{
  "model": "claude-3-5-sonnet",
  "max_tokens": 100,
  "system": "You are helpful.",
  "messages": [
    {"role": "user", "content": "Hello!"}
  ],
  "temperature": 0.7,
  "stop_sequences": ["Human:", "AI:"]
}

// è½¬æ¢å (OpenAIæ ¼å¼)
{
  "model": "gpt-4o",
  "messages": [
    {"role": "system", "content": "You are helpful."},
    {"role": "user", "content": "Hello!"}
  ],
  "max_tokens": 100,
  "temperature": 0.7,
  "stop": ["Human:", "AI:"]
}
```

---

## é”™è¯¯å“åº”æ ¼å¼

### OpenAI é”™è¯¯æ ¼å¼

```json
{
  "error": {
    "message": "Invalid model name",
    "type": "invalid_request_error",
    "param": "model",
    "code": "invalid_model"
  }
}
```

### Anthropic é”™è¯¯æ ¼å¼

```json
{
  "error": {
    "type": "invalid_request_error",
    "message": "Invalid model name"
  }
}
```

### é€šç”¨é”™è¯¯ç 

| HTTPçŠ¶æ€ç  | é”™è¯¯ç±»å‹ | æè¿° |
|------------|----------|------|
| 400 | `invalid_request_error` | è¯·æ±‚å‚æ•°é”™è¯¯ |
| 401 | `authentication_error` | è®¤è¯å¤±è´¥ |
| 403 | `permission_error` | æƒé™ä¸è¶³ |
| 404 | `not_found_error` | èµ„æºä¸å­˜åœ¨ |
| 429 | `rate_limit_error` | è¯·æ±‚é¢‘ç‡è¶…é™ |
| 500 | `server_error` | æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ |
| 502 | `upstream_error` | ä¸Šæ¸¸æœåŠ¡é”™è¯¯ |

---

## Streamæ ¼å¼è§„èŒƒ

### OpenAI Streamæ ¼å¼

**å¼€å§‹ï¼š**
```
data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1677652288,"model":"gpt-4o","choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":null}]}

```

**å†…å®¹ï¼š**
```
data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1677652288,"model":"gpt-4o","choices":[{"index":0,"delta":{"content":"Hello"},"finish_reason":null}]}

data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1677652288,"model":"gpt-4o","choices":[{"index":0,"delta":{"content":" world"},"finish_reason":null}]}

```

**ç»“æŸï¼š**
```
data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1677652288,"model":"gpt-4o","choices":[{"index":0,"delta":{},"finish_reason":"stop"}],"usage":{"prompt_tokens":10,"completion_tokens":8,"total_tokens":18}}

data: [DONE]
```

### Anthropic Streamæ ¼å¼

**å¼€å§‹ï¼š**
```
event: message_start
data: {"type":"message_start","message":{"id":"msg_123","type":"message","role":"assistant","content":[],"model":"claude-3-5-sonnet","stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":10,"output_tokens":0}}}

```

**å†…å®¹ï¼š**
```
event: content_block_start
data: {"type":"content_block_start","index":0,"content_block":{"type":"text","text":""}}

event: ping
data: {"type":"ping"}

event: content_block_delta
data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":"Hello"}}

event: content_block_delta
data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":" world"}}

```

**ç»“æŸï¼š**
```
event: content_block_stop
data: {"type":"content_block_stop","index":0}

event: message_delta
data: {"type":"message_delta","delta":{"stop_reason":"end_turn","stop_sequence":null},"usage":{"output_tokens":8}}

event: message_stop
data: {"type":"message_stop"}
```

---

## æœ€ä½³å®è·µ

### æ¨¡å‹é€‰æ‹©å»ºè®®

**OpenAIæ¨¡å‹ï¼š**
- **é€šç”¨å¯¹è¯**: `gpt-4o` - æœ€æ–°æœ€å¼ºå¤§çš„æ¨¡å‹
- **å¿«é€Ÿå“åº”**: `gpt-4o-mini` - å¿«é€Ÿä¸”ç»æµçš„é€‰æ‹©
- **ä»£ç ç”Ÿæˆ**: `gpt-4o` - ä»£ç èƒ½åŠ›å¼º

**Anthropicæ¨¡å‹ï¼š**
- **å¹³è¡¡æ€§èƒ½**: `claude-3-5-sonnet` - æ€§èƒ½ä¸é€Ÿåº¦å¹³è¡¡
- **å¿«é€Ÿé—®ç­”**: `claude-3-5-haiku` - å“åº”é€Ÿåº¦å¿«ï¼Œæˆæœ¬ä½
- **å¤æ‚æ¨ç†**: `claude-opus-4-1` - æ¨ç†èƒ½åŠ›å¼º

### å‚æ•°è°ƒä¼˜å»ºè®®

**æ¸©åº¦å‚æ•°ï¼š**
- **åˆ›é€ æ€§ä»»åŠ¡**: 0.7-1.0
- **äº‹å®æ€§å›ç­”**: 0.0-0.3
- **å¹³è¡¡ä½¿ç”¨**: 0.3-0.7

**Tokené™åˆ¶ï¼š**
- **ç®€çŸ­å›ç­”**: 100-500 tokens
- **è¯¦ç»†è§£é‡Š**: 500-2000 tokens
- **é•¿æ–‡æ¡£**: 2000+ tokens

**åœæ­¢åºåˆ—ï¼š**
- **å¯¹è¯æ§åˆ¶**: è®¾ç½®æ˜ç¡®çš„ç»“æŸæ ‡è®°
- **æ ¼å¼æ§åˆ¶**: æ§åˆ¶è¾“å‡ºæ ¼å¼
- **é•¿åº¦æ§åˆ¶**: é¿å…è¿‡é•¿å›å¤

### é”™è¯¯å¤„ç†å»ºè®®

1. **é‡è¯•æœºåˆ¶**: å®ç°æŒ‡æ•°é€€é¿é‡è¯•
2. **é™çº§ç­–ç•¥**: å¤±è´¥æ—¶åˆ‡æ¢åˆ°å¤‡ç”¨æ¨¡å‹
3. **ç›‘æ§å‘Šè­¦**: è®¾ç½®é”™è¯¯ç‡ç›‘æ§
4. **æ—¥å¿—è®°å½•**: è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **è¿æ¥å¤ç”¨**: ä½¿ç”¨HTTPè¿æ¥æ± 
2. **æ‰¹é‡è¯·æ±‚**: åˆå¹¶å¤šä¸ªå°è¯·æ±‚
3. **ç¼“å­˜ç­–ç•¥**: ç¼“å­˜å¸¸è§è¯·æ±‚ç»“æœ
4. **å¼‚æ­¥å¤„ç†**: éé˜»å¡è¯·æ±‚å¤„ç†

---

## æ›´æ–°è®°å½•

- **2025-01-XX**: æ›´æ–°æ¨¡å‹åç§°ï¼Œå°†è¿‡æ—¶çš„æ¨¡å‹åç§°æ›´æ–°ä¸ºæœ€æ–°ç‰ˆæœ¬
- **2025-XX-XX**: åˆå§‹ç‰ˆæœ¬ï¼Œæ”¯æŒOpenAIå’ŒAnthropicæ ¼å¼