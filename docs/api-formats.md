# LLM Gateway API æ ¼å¼è§„èŒƒ

æœ¬æ–‡æ¡£è¯¦ç»†æè¿°äº†LLM Gatewayæ”¯æŒçš„ä¸¤ç§ä¸»è¦APIæ ¼å¼ï¼šOpenAIæ ¼å¼å’ŒAnthropicæ ¼å¼ã€‚

## ç›®å½•

1. [æ ¸å¿ƒå·®å¼‚å¯¹æ¯”](#æ ¸å¿ƒå·®å¼‚å¯¹æ¯”)
2. [OpenAI API æ ¼å¼](#openai-api-æ ¼å¼)
3. [Anthropic API æ ¼å¼](#anthropic-api-æ ¼å¼)
4. [æ ¼å¼æ£€æµ‹è§„åˆ™](#æ ¼å¼æ£€æµ‹è§„åˆ™)
5. [æ ¼å¼è½¬æ¢æ˜ å°„](#æ ¼å¼è½¬æ¢æ˜ å°„)
6. [é”™è¯¯å“åº”æ ¼å¼](#é”™è¯¯å“åº”æ ¼å¼)
7. [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## æ ¸å¿ƒå·®å¼‚å¯¹æ¯”

### ğŸ“Š ä¸»è¦ç‰¹æ€§å¯¹æ¯”

| ç‰¹æ€§ | OpenAI | Anthropic |
|------|--------|-----------|
| **ä¸»è¦ç«¯ç‚¹** | `/v1/chat/completions` | `/v1/messages` |
| **ç³»ç»Ÿæ¶ˆæ¯** | `messages`æ•°ç»„ä¸­çš„`system`è§’è‰² | ç‹¬ç«‹çš„`system`å­—æ®µ |
| **å¿…éœ€å­—æ®µ** | `model`, `messages` | `model`, `max_tokens`, `messages` |
| **æ¨¡å‹å‘½å** | `gpt-3.5-turbo`, `gpt-4` | `claude-3-sonnet`, `claude-3-haiku` |
| **åœæ­¢å‚æ•°** | `stop` (array/string) | `stop_sequences` (array) |
| **Tokenç»Ÿè®¡** | `prompt_tokens`, `completion_tokens` | `input_tokens`, `output_tokens` |
| **æ¸©åº¦èŒƒå›´** | 0.0 - 2.0 | 0.0 - 1.0 |
| **è§’è‰²æ”¯æŒ** | `system`, `user`, `assistant`, `function` | `user`, `assistant` |

### ğŸ”§ è¯·æ±‚æ ¼å¼å¯¹æ¯”

**OpenAI è¯·æ±‚ç¤ºä¾‹ï¼š**
```json
{
  "model": "gpt-3.5-turbo",
  "messages": [
    {"role": "system", "content": "You are helpful."},
    {"role": "user", "content": "Hello!"}
  ],
  "max_tokens": 100,
  "temperature": 0.7,
  "stop": ["Human:", "AI:"]
}
```

**Anthropic è¯·æ±‚ç¤ºä¾‹ï¼š**
```json
{
  "model": "claude-3-sonnet",
  "max_tokens": 100,
  "system": "You are helpful.",
  "messages": [
    {"role": "user", "content": "Hello!"}
  ],
  "temperature": 0.7,
  "stop_sequences": ["Human:", "AI:"]
}
```

### ğŸ“¤ å“åº”æ ¼å¼å¯¹æ¯”

**OpenAI å“åº”ï¼š**
```json
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "choices": [{
    "message": {
      "role": "assistant",
      "content": "Hello! How can I help you?"
    },
    "finish_reason": "stop"
  }],
  "usage": {
    "prompt_tokens": 20,
    "completion_tokens": 10,
    "total_tokens": 30
  }
}
```

**Anthropic å“åº”ï¼š**
```json
{
  "id": "msg_123", 
  "type": "message",
  "role": "assistant",
  "content": [{
    "type": "text",
    "text": "Hello! How can I help you?"
  }],
  "stop_reason": "end_turn",
  "usage": {
    "input_tokens": 20,
    "output_tokens": 10
  }
}
```

---

## OpenAI API æ ¼å¼

### 1.1 Chat Completions API

**ç«¯ç‚¹ï¼š** `POST /v1/chat/completions`

**è¯·æ±‚æ ¼å¼ï¼š**

```json
{
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful assistant."
    },
    {
      "role": "user", 
      "content": "Hello, how are you?"
    },
    {
      "role": "assistant",
      "content": "I'm doing well, thank you!"
    }
  ],
  "max_tokens": 150,
  "temperature": 0.7,
  "top_p": 1.0,
  "n": 1,
  "stream": false,
  "stop": ["Human:", "AI:"],
  "presence_penalty": 0.0,
  "frequency_penalty": 0.0,
  "logit_bias": {},
  "user": "user123"
}
```

**å“åº”æ ¼å¼ï¼š**

```json
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "created": 1677652288,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Hello! I'm an AI assistant. How can I help you today?"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 56,
    "completion_tokens": 31,
    "total_tokens": 87
  }
}
```

### 1.2 Text Completions API (Legacy)

**ç«¯ç‚¹ï¼š** `POST /v1/completions`

**è¯·æ±‚æ ¼å¼ï¼š**

```json
{
  "model": "text-davinci-003",
  "prompt": "Translate the following English text to French: 'Hello, world!'",
  "max_tokens": 60,
  "temperature": 0.7,
  "top_p": 1.0,
  "n": 1,
  "stream": false,
  "stop": ["\n"],
  "presence_penalty": 0.0,
  "frequency_penalty": 0.0,
  "best_of": 1,
  "logit_bias": {},
  "user": "user123"
}
```

**å“åº”æ ¼å¼ï¼š**

```json
{
  "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
  "object": "text_completion", 
  "created": 1589478378,
  "model": "text-davinci-003",
  "choices": [
    {
      "text": "\n\nBonjour, le monde!",
      "index": 0,
      "logprobs": null,
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 5,
    "completion_tokens": 7,
    "total_tokens": 12
  }
}
```

### 1.3 OpenAI å­—æ®µè¯´æ˜

#### è¯·æ±‚å­—æ®µï¼š

| å­—æ®µå | ç±»å‹ | å¿…éœ€ | æè¿° |
|--------|------|------|------|
| `model` | string | âœ… | æ¨¡å‹æ ‡è¯†ç¬¦ (å¦‚: gpt-3.5-turbo, gpt-4) |
| `messages` | array | âœ… | æ¶ˆæ¯æ•°ç»„ (Chat API) |
| `prompt` | string | âœ… | æ–‡æœ¬æç¤º (Completion API) |
| `max_tokens` | integer | âŒ | æœ€å¤§ç”Ÿæˆtokenæ•° |
| `temperature` | number | âŒ | éšæœºæ€§æ§åˆ¶ (0.0-2.0) |
| `top_p` | number | âŒ | æ ¸é‡‡æ ·å‚æ•° (0.0-1.0) |
| `n` | integer | âŒ | ç”Ÿæˆé€‰æ‹©æ•°é‡ |
| `stream` | boolean | âŒ | æ˜¯å¦æµå¼å“åº” |
| `stop` | array/string | âŒ | åœæ­¢åºåˆ— |
| `presence_penalty` | number | âŒ | å­˜åœ¨æƒ©ç½š (-2.0-2.0) |
| `frequency_penalty` | number | âŒ | é¢‘ç‡æƒ©ç½š (-2.0-2.0) |
| `logit_bias` | object | âŒ | logitåç½® |
| `user` | string | âŒ | ç”¨æˆ·æ ‡è¯† |

#### æ¶ˆæ¯è§’è‰²ï¼š

- `system`: ç³»ç»Ÿæ¶ˆæ¯ï¼Œè®¾ç½®AIè¡Œä¸º
- `user`: ç”¨æˆ·æ¶ˆæ¯  
- `assistant`: AIåŠ©æ‰‹å“åº”
- `function`: å‡½æ•°è°ƒç”¨ç»“æœ (Functions API)

---

## Anthropic API æ ¼å¼

### 2.1 Messages API

**ç«¯ç‚¹ï¼š** `POST /v1/messages`

**è¯·æ±‚æ ¼å¼ï¼š**

```json
{
  "model": "claude-3-sonnet-20240229",
  "max_tokens": 1024,
  "messages": [
    {
      "role": "user",
      "content": "Hello, Claude"
    }
  ],
  "system": "You are a helpful AI assistant.",
  "temperature": 0.7,
  "top_p": 0.9,
  "top_k": 40,
  "stop_sequences": ["Human:", "Assistant:"],
  "stream": false,
  "metadata": {
    "user_id": "user123"
  }
}
```

**å“åº”æ ¼å¼ï¼š**

```json
{
  "id": "msg_01XFDUDYJgAACzvnptvVoYEL",
  "type": "message",
  "role": "assistant", 
  "content": [
    {
      "type": "text",
      "text": "Hello! I'm Claude, an AI assistant. How can I help you today?"
    }
  ],
  "model": "claude-3-sonnet-20240229",
  "stop_reason": "end_turn",
  "stop_sequence": null,
  "usage": {
    "input_tokens": 10,
    "output_tokens": 25
  }
}
```

### 2.2 Anthropic å­—æ®µè¯´æ˜

#### è¯·æ±‚å­—æ®µï¼š

| å­—æ®µå | ç±»å‹ | å¿…éœ€ | æè¿° |
|--------|------|------|------|
| `model` | string | âœ… | æ¨¡å‹æ ‡è¯†ç¬¦ (å¦‚: claude-3-sonnet-20240229) |
| `max_tokens` | integer | âœ… | æœ€å¤§ç”Ÿæˆtokenæ•° |
| `messages` | array | âœ… | æ¶ˆæ¯æ•°ç»„ |
| `system` | string | âŒ | ç³»ç»Ÿæç¤º |
| `temperature` | number | âŒ | éšæœºæ€§æ§åˆ¶ (0.0-1.0) |
| `top_p` | number | âŒ | æ ¸é‡‡æ ·å‚æ•° (0.0-1.0) |
| `top_k` | integer | âŒ | Top-Ké‡‡æ ·å‚æ•° |
| `stop_sequences` | array | âŒ | åœæ­¢åºåˆ— |
| `stream` | boolean | âŒ | æ˜¯å¦æµå¼å“åº” |
| `metadata` | object | âŒ | å…ƒæ•°æ®ä¿¡æ¯ |

#### æ¶ˆæ¯è§’è‰²ï¼š

- `user`: ç”¨æˆ·æ¶ˆæ¯
- `assistant`: ClaudeåŠ©æ‰‹å“åº”

**æ³¨æ„ï¼š** Anthropicä¸ä½¿ç”¨`system`è§’è‰²ï¼Œè€Œæ˜¯ä½¿ç”¨å•ç‹¬çš„`system`å­—æ®µã€‚

### 2.3 æ”¯æŒçš„Claudeæ¨¡å‹

| æ¨¡å‹åç§° | æ ‡è¯†ç¬¦ | æè¿° |
|----------|--------|------|
| Claude 3 Opus | `claude-3-opus-20240229` | æœ€å¼ºå¤§çš„æ¨¡å‹ |
| Claude 3 Sonnet | `claude-3-sonnet-20240229` | å¹³è¡¡æ€§èƒ½å’Œé€Ÿåº¦ |
| Claude 3 Haiku | `claude-3-haiku-20240307` | å¿«é€Ÿå“åº”æ¨¡å‹ |

---

## æ ¼å¼æ£€æµ‹è§„åˆ™

LLM Gatewayä½¿ç”¨ä»¥ä¸‹è§„åˆ™è‡ªåŠ¨æ£€æµ‹è¯·æ±‚æ ¼å¼ï¼š

### 3.1 æ£€æµ‹é€»è¾‘

```go
func (t *Transformer) DetectFormat(requestBody []byte) RequestFormat {
    var data map[string]interface{}
    if err := json.Unmarshal(requestBody, &data); err != nil {
        return FormatUnknown
    }

    // æ£€æŸ¥æ˜¯å¦æœ‰Anthropicç‰¹æœ‰çš„å­—æ®µ
    if _, hasMessages := data["messages"]; hasMessages {
        if model, hasModel := data["model"].(string); hasModel {
            if strings.Contains(model, "claude") || strings.Contains(model, "anthropic") {
                return FormatAnthropic
            }
        }
        // é»˜è®¤è®¤ä¸ºæ˜¯OpenAIæ ¼å¼
        return FormatOpenAI
    }

    // æ£€æŸ¥æ˜¯å¦æœ‰æ—§ç‰ˆæœ¬çš„promptå­—æ®µ
    if _, hasPrompt := data["prompt"]; hasPrompt {
        return FormatOpenAI
    }

    return FormatUnknown
}
```

### 3.2 æ£€æµ‹è§„åˆ™è¡¨

| æ¡ä»¶ | æ£€æµ‹ç»“æœ |
|------|----------|
| åŒ…å«`messages`å­—æ®µ + æ¨¡å‹ååŒ…å«"claude" | `FormatAnthropic` |
| åŒ…å«`messages`å­—æ®µ + æ¨¡å‹ååŒ…å«"anthropic" | `FormatAnthropic` |
| åŒ…å«`messages`å­—æ®µ + å…¶ä»–æ¨¡å‹å | `FormatOpenAI` |
| åŒ…å«`prompt`å­—æ®µ | `FormatOpenAI` |
| éƒ½ä¸åŒ…å« | `FormatUnknown` |

---

## æ ¼å¼è½¬æ¢æ˜ å°„

### 4.1 è¯·æ±‚å­—æ®µæ˜ å°„

| OpenAI | Anthropic | è½¬æ¢è§„åˆ™ |
|--------|-----------|----------|
| `messages[].role="system"` | `system` | æå–systemæ¶ˆæ¯åˆ°å•ç‹¬å­—æ®µ |
| `messages[].role="user"` | `messages[].role="user"` | ç›´æ¥æ˜ å°„ |
| `messages[].role="assistant"` | `messages[].role="assistant"` | ç›´æ¥æ˜ å°„ |
| `max_tokens` | `max_tokens` | ç›´æ¥æ˜ å°„ |
| `temperature` | `temperature` | ç›´æ¥æ˜ å°„ |
| `top_p` | `top_p` | ç›´æ¥æ˜ å°„ |
| `stop` | `stop_sequences` | å­—æ®µåè½¬æ¢ |
| `stream` | `stream` | ç›´æ¥æ˜ å°„ |

### 4.2 å“åº”å­—æ®µæ˜ å°„

| Anthropic | OpenAI | è½¬æ¢è§„åˆ™ |
|-----------|---------|----------|
| `id` | `id` | ç›´æ¥æ˜ å°„ |
| `content[0].text` | `choices[0].message.content` | æå–æ–‡æœ¬å†…å®¹ |
| `model` | `model` | ç›´æ¥æ˜ å°„ |
| `stop_reason` | `choices[0].finish_reason` | åœæ­¢åŸå› æ˜ å°„ |
| `usage.input_tokens` | `usage.prompt_tokens` | å­—æ®µåè½¬æ¢ |
| `usage.output_tokens` | `usage.completion_tokens` | å­—æ®µåè½¬æ¢ |

### 4.3 åœæ­¢åŸå› æ˜ å°„

| Anthropic | OpenAI | æè¿° |
|-----------|---------|------|
| `end_turn` | `stop` | æ­£å¸¸ç»“æŸ |
| `max_tokens` | `length` | è¾¾åˆ°æœ€å¤§é•¿åº¦ |
| `stop_sequence` | `stop` | é‡åˆ°åœæ­¢åºåˆ— |

---

## é”™è¯¯å“åº”æ ¼å¼

### 5.1 OpenAI é”™è¯¯æ ¼å¼

```json
{
  "error": {
    "message": "Invalid API key provided",
    "type": "invalid_request_error",
    "param": null,
    "code": "invalid_api_key"
  }
}
```

### 5.2 Anthropic é”™è¯¯æ ¼å¼

```json
{
  "type": "error",
  "error": {
    "type": "authentication_error",
    "message": "Invalid API key"
  }
}
```

### 5.3 LLM Gateway ç»Ÿä¸€é”™è¯¯æ ¼å¼

Gatewayè¿”å›OpenAIå…¼å®¹çš„é”™è¯¯æ ¼å¼ï¼š

```json
{
  "error": {
    "message": "é”™è¯¯æè¿°",
    "type": "é”™è¯¯ç±»å‹",
    "code": "é”™è¯¯ä»£ç "
  },
  "timestamp": 1677652288
}
```

### 5.4 å¸¸è§é”™è¯¯ç±»å‹

| é”™è¯¯ç±»å‹ | HTTPçŠ¶æ€ç  | æè¿° |
|----------|------------|------|
| `missing_authorization` | 401 | ç¼ºå°‘Authorizationå¤´ |
| `invalid_api_key` | 401 | æ— æ•ˆçš„APIå¯†é’¥ |
| `unsupported_format` | 400 | ä¸æ”¯æŒçš„è¯·æ±‚æ ¼å¼ |
| `invalid_request_body` | 400 | æ— æ•ˆçš„è¯·æ±‚ä½“ |
| `request_transform_error` | 400 | è¯·æ±‚è½¬æ¢å¤±è´¥ |
| `no_upstream_available` | 503 | æ— å¯ç”¨ä¸Šæ¸¸æœåŠ¡ |
| `upstream_error` | 502 | ä¸Šæ¸¸æœåŠ¡é”™è¯¯ |
| `rate_limit_exceeded` | 429 | è¶…è¿‡é€Ÿç‡é™åˆ¶ |

---

## ä½¿ç”¨ç¤ºä¾‹

### 6.1 å‘é€OpenAIæ ¼å¼è¯·æ±‚

```bash
curl -X POST "http://localhost:3847/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_GATEWAY_API_KEY" \
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [
      {"role": "user", "content": "Hello!"}
    ],
    "max_tokens": 100
  }'
```

### 6.2 å‘é€Anthropicæ ¼å¼è¯·æ±‚

```bash
curl -X POST "http://localhost:3847/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_GATEWAY_API_KEY" \
  -d '{
    "model": "claude-3-sonnet",
    "messages": [
      {"role": "user", "content": "Hello!"}
    ],
    "max_tokens": 100
  }'
```

### 6.3 ä½¿ç”¨AnthropicåŸç”Ÿç«¯ç‚¹

```bash
curl -X POST "http://localhost:3847/v1/messages" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_GATEWAY_API_KEY" \
  -d '{
    "model": "claude-3-haiku",
    "max_tokens": 100,
    "messages": [
      {"role": "user", "content": "Hello!"}
    ]
  }'
```

---

## æœ€ä½³å®è·µ

### ğŸ¯ æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨

**OpenAI æ¨¡å‹ï¼š**
| æ¨¡å‹ | æ ‡è¯†ç¬¦ | ç”¨é€” |
|------|--------|------|
| GPT-3.5 Turbo | `gpt-3.5-turbo` | é€šç”¨å¯¹è¯ |
| GPT-4 | `gpt-4` | é«˜çº§æ¨ç† |
| GPT-4 Turbo | `gpt-4-turbo` | å¿«é€Ÿé«˜çº§æ¨ç† |
| Text Davinci | `text-davinci-003` | æ–‡æœ¬å®Œæˆ(æ—§ç‰ˆ) |

**Anthropic æ¨¡å‹ï¼š**
| æ¨¡å‹ | æ ‡è¯†ç¬¦ | ç”¨é€” |
|------|--------|------|
| Claude 3 Opus | `claude-3-opus-20240229` | æœ€å¼ºæ¨ç†èƒ½åŠ› |
| Claude 3 Sonnet | `claude-3-sonnet-20240229` | å¹³è¡¡æ€§èƒ½ |
| Claude 3 Haiku | `claude-3-haiku-20240307` | å¿«é€Ÿå“åº” |

### âš™ï¸ å®Œæ•´å‚æ•°æ˜ å°„è¡¨

| åŠŸèƒ½ | OpenAIå‚æ•° | Anthropicå‚æ•° | è½¬æ¢è¯´æ˜ |
|------|------------|---------------|----------|
| æ¨¡å‹é€‰æ‹© | `model` | `model` | ç›´æ¥æ˜ å°„ |
| æœ€å¤§é•¿åº¦ | `max_tokens` (å¯é€‰) | `max_tokens` (å¿…éœ€) | Anthropicå¿…éœ€ |
| éšæœºæ€§ | `temperature` (0.0-2.0) | `temperature` (0.0-1.0) | èŒƒå›´ä¸åŒ |
| æ ¸é‡‡æ · | `top_p` | `top_p` | ç›´æ¥æ˜ å°„ |
| Top-Ké‡‡æ · | âŒ | `top_k` | Anthropicç‹¬æœ‰ |
| åœæ­¢è¯ | `stop` | `stop_sequences` | å­—æ®µåä¸åŒ |
| ç³»ç»Ÿæç¤º | `messages[role=system]` | `system` | ç»“æ„è½¬æ¢ |
| æµå¼è¾“å‡º | `stream` | `stream` | ç›´æ¥æ˜ å°„ |
| ç”¨æˆ·æ ‡è¯† | `user` | `metadata.user_id` | ç»“æ„ä¸åŒ |
| å­˜åœ¨æƒ©ç½š | `presence_penalty` | âŒ | OpenAIç‹¬æœ‰ |
| é¢‘ç‡æƒ©ç½š | `frequency_penalty` | âŒ | OpenAIç‹¬æœ‰ |
| logitåç½® | `logit_bias` | âŒ | OpenAIç‹¬æœ‰ |

### ğŸš« é”™è¯¯ä»£ç å¯¹æ¯”

| é”™è¯¯ç±»å‹ | OpenAI | Anthropic | Gatewayç»Ÿä¸€ |
|----------|---------|-----------|-------------|
| è®¤è¯é”™è¯¯ | `invalid_api_key` | `authentication_error` | `invalid_api_key` |
| è¯·æ±‚é”™è¯¯ | `invalid_request_error` | `invalid_request_error` | `invalid_request_error` |
| é€Ÿç‡é™åˆ¶ | `rate_limit_exceeded` | `rate_limit_error` | `rate_limit_exceeded` |
| æœåŠ¡é”™è¯¯ | `server_error` | `api_error` | `server_error` |
| è¶…é•¿è¾“å…¥ | `context_length_exceeded` | `invalid_request_error` | `context_length_exceeded` |

### ğŸ’¡ ä½¿ç”¨å»ºè®®

**1. Gatewayä½¿ç”¨å»ºè®®ï¼š**
- **ç»Ÿä¸€ä½¿ç”¨OpenAIæ ¼å¼**ï¼šå®¢æˆ·ç«¯ç»Ÿä¸€ä½¿ç”¨OpenAIæ ¼å¼ï¼ŒGatewayè‡ªåŠ¨è½¬æ¢
- **æ˜ç¡®æŒ‡å®šæ¨¡å‹**ï¼šä½¿ç”¨å®Œæ•´çš„æ¨¡å‹æ ‡è¯†ç¬¦é¿å…æ­§ä¹‰
- **åˆç†è®¾ç½®è¶…æ—¶**ï¼šè€ƒè™‘ä¸åŒæ¨¡å‹çš„å“åº”æ—¶é—´å·®å¼‚
- **é”™è¯¯å¤„ç†**ï¼šç»Ÿä¸€å¤„ç†Gatewayè¿”å›çš„OpenAIæ ¼å¼é”™è¯¯

**2. æ¨¡å‹é€‰æ‹©å»ºè®®ï¼š**
| åœºæ™¯ | æ¨èæ¨¡å‹ | ç†ç”± |
|------|----------|------|
| å¿«é€Ÿé—®ç­” | `claude-3-haiku` | å“åº”é€Ÿåº¦å¿«ï¼Œæˆæœ¬ä½ |
| å¤æ‚æ¨ç† | `claude-3-opus` æˆ– `gpt-4` | æ¨ç†èƒ½åŠ›å¼º |
| é€šç”¨å¯¹è¯ | `claude-3-sonnet` æˆ– `gpt-3.5-turbo` | æ€§èƒ½å¹³è¡¡ |
| ä»£ç ç”Ÿæˆ | `gpt-4` | ä»£ç èƒ½åŠ›å¼º |
| åˆ›æ„å†™ä½œ | `claude-3-opus` | åˆ›æ„èƒ½åŠ›å¼º |

**3. æˆæœ¬ä¼˜åŒ–å»ºè®®ï¼š**
- ä¼˜å…ˆä½¿ç”¨Haikuæ¨¡å‹å¤„ç†ç®€å•è¯·æ±‚
- åˆç†è®¾ç½®`max_tokens`æ§åˆ¶æˆæœ¬
- ä½¿ç”¨ç³»ç»Ÿæç¤ºå¼•å¯¼æ¨¡å‹ç»™å‡ºç®€æ´å›ç­”
- å®æ–½è¯·æ±‚ç¼“å­˜é¿å…é‡å¤è°ƒç”¨

### ğŸ” æ ¼å¼æ£€æµ‹æµç¨‹å›¾

```
è¯·æ±‚åŒ…å«å­—æ®µæ£€æŸ¥ï¼š
â”œâ”€â”€ æœ‰ "messages" å­—æ®µï¼Ÿ
â”‚   â”œâ”€â”€ æ˜¯ â†’ æ£€æŸ¥ "model" å­—æ®µ
â”‚   â”‚   â”œâ”€â”€ åŒ…å« "claude" â†’ Anthropicæ ¼å¼
â”‚   â”‚   â”œâ”€â”€ åŒ…å« "anthropic" â†’ Anthropicæ ¼å¼  
â”‚   â”‚   â””â”€â”€ å…¶ä»– â†’ OpenAIæ ¼å¼
â”‚   â””â”€â”€ å¦ â†’ æ£€æŸ¥ "prompt" å­—æ®µ
â”‚       â”œâ”€â”€ æœ‰ â†’ OpenAIæ ¼å¼ (Legacy)
â”‚       â””â”€â”€ æ—  â†’ Unknownæ ¼å¼
```

---

## æ³¨æ„äº‹é¡¹

1. **æ¨¡å‹åç§°å¤§å°å†™æ•æ„Ÿ**ï¼šæ ¼å¼æ£€æµ‹åŸºäºæ¨¡å‹åç§°ï¼Œç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„å¤§å°å†™ã€‚

2. **å¿…éœ€å­—æ®µå·®å¼‚**ï¼šAnthropicè¦æ±‚`max_tokens`å­—æ®µï¼Œè€ŒOpenAIä¸­æ˜¯å¯é€‰çš„ã€‚

3. **ç³»ç»Ÿæ¶ˆæ¯å¤„ç†**ï¼šOpenAIä½¿ç”¨`messages`æ•°ç»„ä¸­çš„`system`è§’è‰²ï¼ŒAnthropicä½¿ç”¨å•ç‹¬çš„`system`å­—æ®µã€‚

4. **æµå¼å“åº”å·®å¼‚**ï¼šä¸¤ç§APIçš„æµå¼å“åº”æ ¼å¼ä¸åŒï¼Œéœ€è¦ç›¸åº”çš„è½¬æ¢é€»è¾‘ã€‚

5. **é”™è¯¯å¤„ç†**ï¼šGatewayç»Ÿä¸€è¿”å›OpenAIå…¼å®¹çš„é”™è¯¯æ ¼å¼ï¼Œä¾¿äºå®¢æˆ·ç«¯å¤„ç†ã€‚

6. **Tokenä½¿ç”¨ç»Ÿè®¡**ï¼šå­—æ®µåç§°ä¸åŒä½†å«ä¹‰ç›¸åŒï¼ŒGatewayä¼šè¿›è¡Œé€‚å½“è½¬æ¢ã€‚

7. **å‚æ•°èŒƒå›´å·®å¼‚**ï¼šæ³¨æ„temperatureç­‰å‚æ•°çš„å–å€¼èŒƒå›´åœ¨ä¸¤ä¸ªAPIä¸­ä¸åŒã€‚

8. **è§’è‰²æ”¯æŒå·®å¼‚**ï¼šAnthropicä¸æ”¯æŒ`function`è§’è‰²ï¼Œç³»ç»Ÿæ¶ˆæ¯ä½¿ç”¨ç‹¬ç«‹å­—æ®µã€‚